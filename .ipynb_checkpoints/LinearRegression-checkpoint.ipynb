{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e8e1b0",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Load useful packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ee2cf",
   "metadata": {},
   "source": [
    "Before we start, let's load some packages: [numpy](https://numpy.org) (for matrix manipulations), [cvxpy](https://www.cvxpy.org) (convex optimisation) and [matplotlib](https://matplotlib.org) (plotting).\n",
    "\n",
    "Note: if you are using anaconda python you may not have cvxpy installed by default. Install it using the command ``conda install -c conda-forge cvxpy``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa912aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl \n",
    "import cvxpy as cp\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78f3ac",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "### Model fitting\n",
    "\n",
    "Imagine we have some data taken from an experiment and we would like to find a model that fits the data well.\n",
    "\n",
    "Here is some data I took earlier. Can you figure out a good model for this data? How would you verify that your model is a good fit for the data? Once you have a good idea for a model, try using the `linear_model.LinearRegression` function from scikit-learn to test it with the data. How would you verify that your model is a good fit for the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a039016-4f7a-4715-b924-445a17627eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(\n",
    " [[ 0.00000000e+00,  0.00000000e+00],\n",
    "  [ 6.34665183e-01, -3.17875519e+01],\n",
    "  [ 1.26933037e+00, -2.32023022e+01],\n",
    "  [ 1.90399555e+00,  3.79419670e+01],\n",
    "  [ 2.53866073e+00,  1.26075199e+02],\n",
    "  [ 3.17332591e+00,  1.89220638e+02],\n",
    "  [ 3.80799110e+00,  1.76675134e+02],\n",
    "  [ 4.44265628e+00,  6.91241418e+01],\n",
    "  [ 5.07732146e+00, -1.04652717e+02],\n",
    "  [ 5.71198664e+00, -2.74474035e+02],\n",
    "  [ 6.34665183e+00, -3.57770145e+02],\n",
    "  [ 6.98131701e+00, -2.98688617e+02],\n",
    "  [ 7.61598219e+00, -9.91420759e+01],\n",
    "  [ 8.25064737e+00,  1.73982909e+02],\n",
    "  [ 8.88531256e+00,  4.11258797e+02],\n",
    "  [ 9.51997774e+00,  5.05229741e+02],\n",
    "  [ 1.01546429e+01,  3.98655562e+02],\n",
    "  [ 1.07893081e+01,  1.14999569e+02],\n",
    "  [ 1.14239733e+01, -2.43965862e+02],\n",
    "  [ 1.20586385e+01, -5.35019383e+02],\n",
    "  [ 1.26933037e+01, -6.31303684e+02],\n",
    "  [ 1.33279688e+01, -4.77509750e+02],\n",
    "  [ 1.39626340e+01, -1.18487622e+02],\n",
    "  [ 1.45972992e+01,  3.12664733e+02],\n",
    "  [ 1.52319644e+01,  6.44441084e+02],\n",
    "  [ 1.58666296e+01,  7.35819517e+02],\n",
    "  [ 1.65012947e+01,  5.36287512e+02],\n",
    "  [ 1.71359599e+01,  1.11438637e+02],\n",
    "  [ 1.77706251e+01, -3.78178709e+02],\n",
    "  [ 1.84052903e+01, -7.38308389e+02],\n",
    "  [ 1.90399555e+01, -8.18728004e+02],\n",
    "  [ 1.96746207e+01, -5.76123818e+02],\n",
    "  [ 2.03092858e+01, -9.57201989e+01],\n",
    "  [ 2.09439510e+01,  4.38649084e+02],\n",
    "  [ 2.15786162e+01,  8.15508541e+02],\n",
    "  [ 2.22132814e+01,  8.80102753e+02],\n",
    "  [ 2.28479466e+01,  5.98248128e+02],\n",
    "  [ 2.34826118e+01,  7.32287795e+01],\n",
    "  [ 2.41172769e+01, -4.92265228e+02],\n",
    "  [ 2.47519421e+01, -8.75034822e+02],\n",
    "  [ 2.53866073e+01, -9.20139537e+02],\n",
    "  [ 2.60212725e+01, -6.03980010e+02],\n",
    "  [ 2.66559377e+01, -4.58833816e+01],\n",
    "  [ 2.72906028e+01,  5.37270415e+02],\n",
    "  [ 2.79252680e+01,  9.15989573e+02],\n",
    "  [ 2.85599332e+01,  9.39155313e+02],\n",
    "  [ 2.91945984e+01,  5.94724544e+02],\n",
    "  [ 2.98292636e+01,  1.56191361e+01],\n",
    "  [ 3.04639288e+01, -5.71967517e+02],\n",
    "  [ 3.10985939e+01, -9.37586936e+02],\n",
    "  [ 3.17332591e+01, -9.37586936e+02],\n",
    "  [ 3.23679243e+01, -5.71967517e+02],\n",
    "  [ 3.30025895e+01,  1.56191361e+01],\n",
    "  [ 3.36372547e+01,  5.94724544e+02],\n",
    "  [ 3.42719199e+01,  9.39155313e+02],\n",
    "  [ 3.49065850e+01,  9.15989573e+02],\n",
    "  [ 3.55412502e+01,  5.37270415e+02],\n",
    "  [ 3.61759154e+01, -4.58833816e+01],\n",
    "  [ 3.68105806e+01, -6.03980010e+02],\n",
    "  [ 3.74452458e+01, -9.20139537e+02],\n",
    "  [ 3.80799110e+01, -8.75034822e+02],\n",
    "  [ 3.87145761e+01, -4.92265228e+02],\n",
    "  [ 3.93492413e+01,  7.32287795e+01],\n",
    "  [ 3.99839065e+01,  5.98248128e+02],\n",
    "  [ 4.06185717e+01,  8.80102753e+02],\n",
    "  [ 4.12532369e+01,  8.15508541e+02],\n",
    "  [ 4.18879020e+01,  4.38649084e+02],\n",
    "  [ 4.25225672e+01, -9.57201989e+01],\n",
    "  [ 4.31572324e+01, -5.76123818e+02],\n",
    "  [ 4.37918976e+01, -8.18728004e+02],\n",
    "  [ 4.44265628e+01, -7.38308389e+02],\n",
    "  [ 4.50612280e+01, -3.78178709e+02],\n",
    "  [ 4.56958931e+01,  1.11438637e+02],\n",
    "  [ 4.63305583e+01,  5.36287512e+02],\n",
    "  [ 4.69652235e+01,  7.35819517e+02],\n",
    "  [ 4.75998887e+01,  6.44441084e+02],\n",
    "  [ 4.82345539e+01,  3.12664733e+02],\n",
    "  [ 4.88692191e+01, -1.18487622e+02],\n",
    "  [ 4.95038842e+01, -4.77509750e+02],\n",
    "  [ 5.01385494e+01, -6.31303684e+02],\n",
    "  [ 5.07732146e+01, -5.35019383e+02],\n",
    "  [ 5.14078798e+01, -2.43965862e+02],\n",
    "  [ 5.20425450e+01,  1.14999569e+02],\n",
    "  [ 5.26772102e+01,  3.98655562e+02],\n",
    "  [ 5.33118753e+01,  5.05229741e+02],\n",
    "  [ 5.39465405e+01,  4.11258797e+02],\n",
    "  [ 5.45812057e+01,  1.73982909e+02],\n",
    "  [ 5.52158709e+01, -9.91420759e+01],\n",
    "  [ 5.58505361e+01, -2.98688617e+02],\n",
    "  [ 5.64852012e+01, -3.57770145e+02],\n",
    "  [ 5.71198664e+01, -2.74474035e+02],\n",
    "  [ 5.77545316e+01, -1.04652717e+02],\n",
    "  [ 5.83891968e+01,  6.91241418e+01],\n",
    "  [ 5.90238620e+01,  1.76675134e+02],\n",
    "  [ 5.96585272e+01,  1.89220638e+02],\n",
    "  [ 6.02931923e+01,  1.26075199e+02],\n",
    "  [ 6.09278575e+01,  3.79419670e+01],\n",
    "  [ 6.15625227e+01, -2.32023022e+01],\n",
    "  [ 6.21971879e+01, -3.17875519e+01],\n",
    "  [ 6.28318531e+01,  0.00000000e+00]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b9596-cdf1-417a-9f70-8e07d125710f",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "Here is how I created that mystery data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bdc59-f760-43b4-b8dc-209d5315f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 20*np.pi, 100)\n",
    "y = (x**2 - 20*np.pi*x)*np.cos(x)\n",
    "data = np.array([x,y]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335b902-4c4d-4e1b-9727-2cc41750fde9",
   "metadata": {},
   "source": [
    "The first thing we should do is try to plot the data to see if we can recognise anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e57775-8521-451f-876b-45c3e3393ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plt.plot(x,y,'o-')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f4af4-accd-4db9-b509-145ab941c8d8",
   "metadata": {},
   "source": [
    "If we have a good idea for a model that might fit the data, then we can use `linear_model.LinearRegression` to look for the parameters that best fit the data. This looks like the plot of cos(x) modulated by a quadratic so let's try to fit a linear model of that form to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633f2e1-c7b9-4d39-a359-d38e3b953fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.cos(x),x * np.cos(x), x**2 * np.cos(x)]).T\n",
    "fit = LinearRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b60a3-5488-42b8-ac22-b51414ffa212",
   "metadata": {},
   "source": [
    "Now we plot the model against the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14817d7d-3659-412f-bac7-46a4808fb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,fit.predict(X),\"-\",x,y,\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365698a0-6316-49e1-b34f-847d4b5e850c",
   "metadata": {},
   "source": [
    "Now that we have seen a simple example, let's apply what we have learned in the lectures to see if we can reproduce this and in the process understand what Python has done to find a good fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c5f5b-bc27-4b30-87ff-ef589e603d84",
   "metadata": {},
   "source": [
    "### Linear regression for a linear function\n",
    "\n",
    "We will start with a simple problem: find the line that best fits some data by determining the best fit parameters ($\\beta_0$, $\\beta_1$) in our model $f(x)=\\beta_0 + \\beta_1 x$.\n",
    "\n",
    "The first thing we need is to collect some data samples. Normally, this could come from some experimental measurements, but for this example we will just generate some data ourselves.  In the real world we will never have perfectly clean measurements so we will expect some random noise in our samples. To simulate this, we will add some random noise when we're generating the data we want to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427886e6-780e-4c0d-b87e-d18c4a2dac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,11)\n",
    "y = 3 + 2 * x + 0.3*np.random.randn(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1318e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"Dataset\")\n",
    "plt.xlabel(\"Independent variable\")\n",
    "plt.ylabel(\"Dependent variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b564eba-1226-427d-8081-0bb978cf0fc1",
   "metadata": {},
   "source": [
    "If we have a good idea for a model that might fit the data, then we can use _regression_ to look for the parameters that best fit the data. In this case it looks like we should consider a straight line $y(x)= \\beta_1 x + \\beta_0$ as a model. To fit the model to the data, we can use our data samples to write an (overdetermined) linear system of equations $ X \\beta = y$, where\n",
    "$$ X = \\begin{pmatrix} 1 & x_1 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{pmatrix}, \\quad y = \\begin{pmatrix} y_1 \\\\ \\vdots \\\\ y_n \\end{pmatrix}, \\quad \\beta = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\end{pmatrix}$$\n",
    "The matrix $X$ is an example where we have many rows but only two columns so this is an **over-constrained** problem (equivalently, the points don't all sit exactly on a line). As such we won't be able to find a perfect solution ($y$ is not in the column space of $X$). Instead, we can try to find the line that \"best\" fits the data. If we define \"best\" to mean the line that minimises the square of the 2-norm $||X\\beta - y||^2$ then this leads us to regression, in which we instead solve the system $X^T X \\beta = X^T y$, which does have a solution for $\\beta_0$ and $\\beta_1$. \n",
    "\n",
    "Before proceeding we will create our matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491795c-2181-430e-b746-8f8730f50ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.ones(11),x]).T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88acb78-78b3-494b-b4f1-eec42b4eea01",
   "metadata": {},
   "source": [
    "### Fitting model using pseudo-inverse\n",
    "The first method we could use to fit our model to the data is by using SVD and pseudo-inverse.\n",
    "\n",
    "We first compute the SVD decomposition of matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75b217-4ceb-4abc-96fc-6f21e7cc3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "U,Svec,VT = npl.svd(X)\n",
    "print(Svec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579dd79c-25e4-4f1b-a2c4-017ab1d1144c",
   "metadata": {},
   "source": [
    "We now build its pseudo-inverse $X^\\dagger$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db7f28-eb2c-4463-90d0-c4b93bed12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explicitly create the pseudoinverse\n",
    "Sdag = np.zeros(X.T.shape)\n",
    "np.fill_diagonal(Sdag,1/Svec)\n",
    "\n",
    "Xpinv = VT.T@Sdag@U.T\n",
    "Xpinv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21703f09-4d08-4cba-aabd-aeb7cd1c862f",
   "metadata": {},
   "source": [
    "We finally apply the pseudoinverse to $y$ and visualise the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e3e8d-f918-4e7c-957d-bc98769f2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = Xpinv@y\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52171b9c-c5b4-43c1-bb23-8dacc8bd6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "xline = np.array([x[0],x[-1]])\n",
    "yline = beta[0]+beta[1]*xline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(x, y,label='Data')\n",
    "plt.plot(xline,yline,color='r',linestyle='-',linewidth=2,label='Fitted model')\n",
    "plt.title(\"Fitted linear model with pseudoinverse\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2a982-13d7-4be5-ae6e-0afc6fb2abe0",
   "metadata": {},
   "source": [
    "### Fitting model using normal equations\n",
    "\n",
    "The second method we can use is the method of normal equations, for which we need to formulate the problem as an optimisation problem.\n",
    "\n",
    "Considering the system of equations:\n",
    "$$ y = X \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\end{pmatrix} + \\epsilon$$\n",
    "where $\\epsilon$ is a vector of vertical distances of the points from the best fit line,\n",
    "then, the optimisation problem is\n",
    "$$\\min_{\\beta} f(\\beta) = || X\\beta-y ||^2$$\n",
    "\n",
    "Since this is a convex optimisation problem, we can then find the solution by looking for the stationary point, i.e., by checking when the gradient $X^T(X\\beta-y)$ vanishes.\n",
    "\n",
    "This leads to the system of normal equations (i.e. using using $X^T$ to project onto the column space of $X$)\n",
    "$$ X^TX\\beta = X^T y$$\n",
    "Note that $(X^T X)^{-1}$ exists when $X$ has independent columns [$N(A) = N(A^T A)$].\n",
    "\n",
    "Let's try to build it and solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fce8d-e53c-4848-99b6-dd1618b3b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2 = npl.solve(X.T@X,X.T@y)\n",
    "print(beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d876727-3632-47a1-8d91-20a6dfde057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xline = np.array([x[0],x[-1]])\n",
    "yline = beta2[0]+beta2[1]*xline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(x, y,label='Data')\n",
    "plt.plot(xline,yline,color='g',linewidth=2,linestyle='-',label='Fitted model')\n",
    "plt.title(\"Fitted linear model with normal equations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da175ae8-d0f4-437c-aafd-d4699c4b04e3",
   "metadata": {},
   "source": [
    "#### Solving the normal equations through the QR decomposition\n",
    "\n",
    "Recall that we saw that we could solve $X^T X \\hat{\\beta}=X^T y$ efficiently if we had the QR decomposition of $X$.\n",
    "We have $X=QR$, with $Q$ orthogonal and $R$ upper triangular, so\n",
    "$$ X^T X = R^TQ^TQR = R^TR$$\n",
    "and\n",
    "$$ X^T y = R^T Q^T y$$\n",
    "so our problem reduces to\n",
    "$$R \\hat{\\beta} = Q^T y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b241f-702a-4fbf-89fa-215588d47c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q,R = npl.qr(X)\n",
    "\n",
    "beta3 = npl.solve(R, Q.T@y)\n",
    "print(beta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465064bf-671a-4b34-8c35-920e884b60b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xline = np.array([x[0],x[-1]])\n",
    "yline = beta3[0]+beta3[1]*xline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(x, y,label='Data')\n",
    "plt.plot(xline,yline,color='m',linewidth=2,linestyle='-',label='Fitted model')\n",
    "plt.title(\"Fitted linear model with normal equations via QR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c3ed2-ecc0-49c6-9427-671ea211d8ba",
   "metadata": {},
   "source": [
    "### Solve the optimisation problem using gradient descent\n",
    "\n",
    "The optimisation problem can be easily solved via the gradient descent method.\n",
    "The idea is to start from a given approximation $\\beta^{(0)}$ and to update it following the direction of the antigradient, which is the direction of steepest descent of the objective function at each point. The process generates a sequence of solution estimates $\\{\\beta^{(k)}\\}$ which, under certain hypotheses, converges to the true solution.\n",
    "\n",
    "As a simplified case, we consider a basic version which makes use of a fixed step, i.e., in which\n",
    "$$ \\beta^{(k+)} = \\beta^{(k)} - \\alpha \\nabla f(\\beta^{(k)})$$\n",
    "with $\\alpha>0$ fixed parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff293bf7-ec46-4616-87d8-c3516e27ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc_4_LS(A,b,x,tol,maxit): \n",
    "    xvec = [x]\n",
    "    res = A@x-b\n",
    "    alpha = (npl.norm(res) / npl.norm(res@A))**2\n",
    "    gradx = A.T@(res)\n",
    "    funcx = npl.norm(res)**2\n",
    "    iter = 0\n",
    "    converged = False\n",
    "    while not converged and iter<maxit:\n",
    "        x = x - alpha*gradx\n",
    "        xvec = np.vstack([xvec,x])\n",
    "        res = A@x-b\n",
    "        alpha = (npl.norm(res) / npl.norm(res@A))**2\n",
    "        gradx = A.T@(res)\n",
    "        funcx = np.hstack([funcx,npl.norm(res)**2])\n",
    "        iter += 1\n",
    "    \n",
    "    return x,xvec.T,funcx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd66ba-fd36-4794-87f7-2e7e5db03181",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta4 = np.array([0,0])\n",
    "tol=1.e-5\n",
    "maxit = 5\n",
    "\n",
    "beta4,betavec,funvec = grad_desc_4_LS(X,y,beta4,tol,maxit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35dfa0-1717-472f-bf92-054b3b5ffefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(funvec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7ff1e-6ba2-4966-837d-43495c8b9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(0,3,200)\n",
    "yy = np.linspace(0,3,200)\n",
    "Xgrid,Ygrid = np.meshgrid(xx,yy)\n",
    "Z = np.zeros((200,200))\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range (200):\n",
    "        Z[i,j] = npl.norm(X@[Xgrid[i,j],Ygrid[i,j]]-y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb6e8c-3fda-44b5-bbae-a2838e53a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,15))\n",
    "\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "plt.contourf(Xgrid,Ygrid,Z, levels=25)\n",
    "plt.colorbar()\n",
    "plt.plot(betavec[0,:],betavec[1,:], lw = 3, c = \"orange\")\n",
    "\n",
    "ax = fig.add_subplot(2, 1, 2, projection='3d')\n",
    "n = 150\n",
    "ax.contour3D(Xgrid,Ygrid,Z, n, alpha = .5)\n",
    "ax.plot(betavec[0,:],betavec[1,:],funvec, c = \"orange\", lw = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9b97c-afea-41df-89cb-181d4e21ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xline = np.array([x[0],x[-1]])\n",
    "yline = beta4[0]+beta4[1]*xline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(x, y,label='Data')\n",
    "plt.plot(xline,yline,color='m',linewidth=2,linestyle='-',label='Fitted model')\n",
    "plt.title(\"Fitted linear model with gradient descent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ed3b3-dd17-4fd1-9a37-4df431190b9b",
   "metadata": {},
   "source": [
    "### Solve the optimisation problem using CVXPY\n",
    "CVXPY is a package for convex optmisation in Python. We can use it to solve least squares problems as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a0da7-90f1-4e79-91a2-4fdadc28f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and solve the CVXPY problem.\n",
    "beta5 = cp.Variable(2)\n",
    "cost = cp.sum_squares(X @ beta5 - y)\n",
    "prob = cp.Problem(cp.Minimize(cost))\n",
    "prob.solve()\n",
    "\n",
    "# Print result.\n",
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"The optimal beta is\")\n",
    "print(beta5.value)\n",
    "print(\"The norm of the residual is \", cp.norm(X @ beta5 - y, p=2).value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7798592-b55a-4afe-acf9-86111ecd7bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xline = np.array([x[0],x[-1]])\n",
    "yline = beta5.value[0]+beta5.value[1]*xline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.scatter(x, y,label='Data')\n",
    "plt.plot(xline,yline,color='y',linewidth=2,linestyle='-',label='Fitted model')\n",
    "plt.title(\"Fitted linear model with CVXPY\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2966d1-f4b9-4547-98ee-9355dcccc743",
   "metadata": {},
   "source": [
    "### Overfitting and under-fitting\n",
    "\n",
    "We might think that we could obtain a better fit by introducing more parameters into our model. Similarly we might think that we could save some time by using fewer parameters. While this might be true in some cases, in many cases  it leads to problems of overfitting and under-fitting, respectively. Let's fit three models to the data, one with too few parameters, one with two many, and one with the correct number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db860da-b7e3-47a6-829b-0a29f50f2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.array([np.ones(x.size)]).T\n",
    "Q,R = npl.qr(X0)\n",
    "beta0 = npl.solve(R, Q.T@y)\n",
    "\n",
    "X1 = np.array([x**i for i in range(0,2)]).T\n",
    "Q,R = npl.qr(X1)\n",
    "beta1 = npl.solve(R, Q.T@y)\n",
    "\n",
    "X10 = np.array([x**i for i in range(0,11)]).T\n",
    "Q,R = npl.qr(X10)\n",
    "beta10 = npl.solve(R, Q.T@y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b245dd-2c19-453a-95fd-d0c64112fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dense = np.linspace(x[0],x[-1],100)\n",
    "X0_dense = np.array([np.ones(x_dense.size)]).T\n",
    "X1_dense = np.array([x_dense**i for i in range(0,2)]).T\n",
    "X10_dense = np.array([x_dense**i for i in range(0,11)]).T\n",
    "\n",
    "plt.plot(x,y,\"o\",x_dense,X0_dense@beta0,x_dense,X1_dense@beta1,x_dense,X10_dense@beta10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51230414-b547-4695-9d08-683cd97af8dd",
   "metadata": {},
   "source": [
    "The green curve representing a 10th order polynomial certainly fits the blue points better (it exactly passes through them all - interpolation!) but it is clearly a worse fit than the orange. We have overfit our model. We could check for this by adding another point (which was not used in the training) and checking if it fits the model.\n",
    "\n",
    "Similarly, the blue line (0th order polynomial) is an underfit and is not a good model for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9b19a-0e7b-4e26-a941-4326a500e170",
   "metadata": {},
   "source": [
    "### Linear Regression for a nonlinear function (but still linear in parameters)\n",
    "\n",
    "There is nothing in linear regression that assumes our model must be a liner function of the variables. Try it with the following nonlinear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5d56c-706c-43dc-bb27-3e48aa122395",
   "metadata": {},
   "outputs": [],
   "source": [
    "xNL = np.linspace(0,2*np.pi,11)\n",
    "yNL = 3 * np.sin(x) + 0.3*np.random.randn(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb89c4f-cbfd-49a8-a545-335698adf680",
   "metadata": {},
   "source": [
    "### Linear Regression in multiple dimensions\n",
    "\n",
    "It is straightforward to generalise linear regression to data in multiple dimensions. Try it with the data generated using the function\n",
    "$f(x,y) = x^2 + y^2 + \\text{random noise}$ using a model of the form\n",
    "$$\\beta_{0,0} + \\beta_{1,0} x + \\beta_{0,1} y + \\beta_{2,0} x^2 + \\beta_{1,1} x y + \\beta_{0,2} y^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d308df-1e78-47f9-aa13-9cdf84bbfacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x2D, y2D, f2D] = np.array([[x,y,x**2 + y**2 + 0.3*np.random.randn()] for x in np.linspace(-5,5,11) for y in np.linspace(-5,5,11)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3117024-929f-42c8-8869-a1fdb65330d4",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "Finally, let's look at an example of Logistic Regression as a method for recognising handwriting. We will consider the well-known MNIST dataset for handwritten digit recognition. The MNIST dataset was created by the National Institute of Standards and Technology in the US and consists of a set of 70,000 images of size 28 x 28 representing handwritten numbers collected from Census Bureau employees and high school students. We can load it through the sklearn.datasets module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810c1d4-a5af-4693-989b-1a487e284dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def plot_digit(digit):  \n",
    "    # A function to plot a vector of length 784 as a 28 x 28 image\n",
    "    digit_image = digit.reshape(28,28)\n",
    "    plt.imshow(digit_image, cmap = plt.get_cmap('gray'))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52192d-10b8-4548-9f9a-f3c614154621",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d461d81-3655-4697-ab52-c9613803ff51",
   "metadata": {},
   "source": [
    "The matrix $X$ is of size 70000 x 784. Each row represents an image of a handwritten digit. Let's look at one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b4c9e-e6d6-49dd-8f95-243ffdee28c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_digit(X[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87eaf4-ff10-401e-b120-ea48459f2267",
   "metadata": {},
   "source": [
    "The corresponding $y$ value is a human-categorised interpretation of what number the image represents. Let's look again at our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b789842-9124-42f5-932a-ce925f51699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d25f0-49f8-493f-b29c-96c1dee0533e",
   "metadata": {},
   "source": [
    "For the sake of time, let's consider a simpler problem with only the digits 0 and 1 present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647e20e-ad4a-4b3f-b579-b0e80567d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_01 = X[np.any([y == \"0\",y == \"1\"], axis = 0)] / 255.0\n",
    "y_01 = y[np.any([y == \"0\",y == \"1\"], axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f35a1f-a465-4f6a-8780-97fa4c78f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_01.shape, y_01.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07b5e2b-1278-475c-8599-045a64adae66",
   "metadata": {},
   "source": [
    "We will further split this into training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee365c-7ad7-41c2-987c-7b4428e42777",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_01_train = X_01[:10000]\n",
    "y_01_train = y_01[:10000]\n",
    "X_01_test = X_01[10000:]\n",
    "y_01_test = y_01[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc74e7a-c5bb-41a0-ac23-da2f9a864e4a",
   "metadata": {},
   "source": [
    "Now let's try to fit this data using regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12666f60-7ebb-4a4a-b8d6-d03081d60037",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfit = LogisticRegression().fit(X_01_train,y_01_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b6093-8b86-45ed-95c2-8a37e9d776a1",
   "metadata": {},
   "source": [
    "Now let's see how it performs on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742fc78-da6f-4ed0-a362-4b45a9eb9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfit.score(X_01_train, y_01_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0646c5-424f-4fe9-b67b-87d68d8ae1ba",
   "metadata": {},
   "source": [
    "Now use the fit to read handwriting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58239a87-dd5d-47ec-a74a-51d15193bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfit.predict(X_01_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc9d8e-88e1-4ceb-82dd-ed746d55526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[plot_digit(d) for d in X_01_train[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5cc93-a3e2-4730-b183-9a4bb1b1675e",
   "metadata": {},
   "source": [
    "Our model is not quite perfect, but it is very good. Let's try it on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5c779-5909-44cb-8267-4a6f49463462",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfit.score(X_01_test, y_01_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c595fb-2e17-4d08-a7e2-b8875c5dfd17",
   "metadata": {},
   "source": [
    "In fact, there is just one mistake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1943a-b599-4e87-b314-10de43df522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((lfit.predict(X_01_test) == y_01_test) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f70f7-74d2-49a1-bd4b-f52814c53320",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfit.predict([X_01_test[4696]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f8f52-a008-4fca-814b-919cedded673",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_01_test[4696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30bea2-7421-43ae-be92-06c4889a49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digit(X_01_test[4696])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
